#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Test d'intÃ©gration pour le provider LOCAL
VÃ©rifie que l'architecture fonctionne correctement mÃªme sans serveur local actif
"""

import sys
import os
from pathlib import Path

# Ajouter le dossier src au path pour les imports
sys.path.insert(0, str(Path(__file__).parent / 'src'))

def test_local_provider_integration():
    """Test complet du provider LOCAL"""
    
    print("=" * 60)
    print("ğŸ§ª TEST D'INTÃ‰GRATION - Provider LOCAL")
    print("=" * 60)
    
    # Test 1: Import et configuration
    print("\nğŸ“¦ Test 1: Imports et configuration...")
    try:
        from src.services.ai_config_service import AIProvider, get_ai_config_service
        from src.services.ai_connection_test_service import get_ai_connection_test_service
        from src.services.openai_service import AIService, get_ai_service
        
        print("  âœ… Imports rÃ©ussis")
        
        # VÃ©rifier que LOCAL est dans l'enum
        assert AIProvider.LOCAL in AIProvider, "LOCAL manquant dans l'enum AIProvider"
        print("  âœ… Provider LOCAL prÃ©sent dans l'enum")
        
    except Exception as e:
        print(f"  âŒ Erreur d'import: {e}")
        return False
    
    # Test 2: Service de configuration
    print("\nâš™ï¸ Test 2: Service de configuration...")
    try:
        config_service = get_ai_config_service()
        
        # Test des modÃ¨les disponibles pour LOCAL
        models = config_service.get_available_models(AIProvider.LOCAL)
        print(f"  ğŸ“‹ ModÃ¨les LOCAL disponibles: {models[:3]}...")
        assert len(models) > 0, "Aucun modÃ¨le LOCAL configurÃ©"
        print("  âœ… ModÃ¨les LOCAL configurÃ©s")
        
        # Test du modÃ¨le par dÃ©faut
        default_model = config_service.get_model(AIProvider.LOCAL)
        print(f"  ğŸ¯ ModÃ¨le par dÃ©faut: {default_model}")
        assert default_model in models, "ModÃ¨le par dÃ©faut invalide"
        print("  âœ… ModÃ¨le par dÃ©faut valide")
        
        # Test de l'URL de base par dÃ©faut
        base_url = config_service.get_base_url(AIProvider.LOCAL)
        print(f"  ğŸŒ URL de base par dÃ©faut: {base_url}")
        assert base_url is not None, "Aucune URL de base configurÃ©e"
        print("  âœ… URL de base configurÃ©e")
        
        # Test de configuration d'une URL personnalisÃ©e
        test_url = "http://localhost:11434"
        config_service.set_base_url(AIProvider.LOCAL, test_url)
        retrieved_url = config_service.get_base_url(AIProvider.LOCAL)
        assert retrieved_url == test_url, "URL de base non sauvegardÃ©e"
        print("  âœ… Configuration URL de base fonctionnelle")
        
    except Exception as e:
        print(f"  âŒ Erreur configuration: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # Test 3: Validation de configuration
    print("\nğŸ” Test 3: Validation de configuration...")
    try:
        validation = config_service.validate_configuration()
        print(f"  ğŸ“Š Configuration valide: {validation['valid']}")
        print(f"  ğŸ”‘ Providers configurÃ©s: {[p.value for p in validation['providers_with_keys']]}")
        
        # LOCAL devrait toujours Ãªtre considÃ©rÃ© comme disponible
        assert AIProvider.LOCAL in validation['providers_with_keys'], "LOCAL non dÃ©tectÃ© comme disponible"
        print("  âœ… LOCAL dÃ©tectÃ© comme provider disponible")
        
    except Exception as e:
        print(f"  âŒ Erreur validation: {e}")
        return False
    
    # Test 4: Service de test de connexion
    print("\nğŸ”§ Test 4: Service de test de connexion...")
    try:
        test_service = get_ai_connection_test_service()
        
        # Test des exigences pour LOCAL
        requirements = test_service.get_connection_requirements(AIProvider.LOCAL)
        print(f"  ğŸ“‹ Exigences LOCAL: {list(requirements.keys())}")
        assert 'client_available' in requirements, "Exigences LOCAL mal configurÃ©es"
        print("  âœ… Exigences LOCAL configurÃ©es")
        
        # Test de connexion (devrait Ã©chouer car pas de serveur)
        print("  ğŸ”„ Test de connexion sans serveur (Ã©chec attendu)...")
        result = test_service.test_connection(
            AIProvider.LOCAL, 
            "http://localhost:11434", 
            "llama3.2"
        )
        print(f"  ğŸ“‹ RÃ©sultat: {result.message}")
        # L'Ã©chec est normal sans serveur local
        assert not result.success, "Connexion rÃ©ussie sans serveur (inattendu)"
        assert result.details.get('error_type') == 'connection_error', "Type d'erreur inattendu"
        print("  âœ… Gestion d'erreur de connexion correcte")
        
    except Exception as e:
        print(f"  âŒ Erreur test connexion: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # Test 5: Service IA principal
    print("\nğŸ¤– Test 5: Service IA principal...")
    try:
        # Test d'initialisation du service IA avec LOCAL (devrait Ã©chouer gracieusement)
        print("  ğŸ”„ Tentative d'initialisation service IA LOCAL...")
        
        try:
            ai_service = AIService(provider=AIProvider.LOCAL, enable_rgpd=True)
            print("  âš ï¸ Service IA initialisÃ© (connexion non testÃ©e)")
            
            # VÃ©rifier les propriÃ©tÃ©s du service
            assert ai_service.provider == AIProvider.LOCAL, "Provider incorrect"
            assert ai_service.enable_rgpd is True, "RGPD non activÃ©"
            print("  âœ… Service IA configurÃ© correctement")
            
            # Test de connexion (devrait Ã©chouer)
            connection_ok = ai_service.test_connection()
            assert not connection_ok, "Test connexion rÃ©ussi sans serveur (inattendu)"
            print("  âœ… Test de connexion Ã©choue comme attendu")
            
        except ValueError as ve:
            if "Aucun fournisseur IA configurÃ©" in str(ve):
                print("  âš ï¸ Service IA nÃ©cessite une configuration prÃ©alable (normal)")
                
                # Configurer LOCAL pour permettre l'initialisation
                config_service.set_enabled_provider(AIProvider.LOCAL)
                ai_service = AIService(provider=AIProvider.LOCAL, enable_rgpd=True)
                print("  âœ… Service IA initialisÃ© aprÃ¨s configuration")
            else:
                raise ve
        
    except Exception as e:
        print(f"  âŒ Erreur service IA: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # Test 6: Interface graphique (imports seulement)
    print("\nğŸ–¥ï¸ Test 6: Interface graphique...")
    try:
        from src.gui.config_window import ConfigWindow
        print("  âœ… Import ConfigWindow rÃ©ussi")
        
        # VÃ©rifier que LOCAL est supportÃ© dans l'interface
        config_window = ConfigWindow()
        display_name = config_window._get_provider_display_name(AIProvider.LOCAL)
        assert display_name == "LLM Local", "Nom d'affichage LOCAL incorrect"
        print(f"  âœ… Nom d'affichage LOCAL: {display_name}")
        
        provider_info = config_window._get_provider_info(AIProvider.LOCAL)
        assert "Local" in provider_info, "Informations LOCAL manquantes"
        print("  âœ… Informations LOCAL configurÃ©es")
        
    except Exception as e:
        print(f"  âŒ Erreur interface: {e}")
        return False
    
    # RÃ©sumÃ© final
    print("\n" + "=" * 60)
    print("âœ… TESTS D'INTÃ‰GRATION LOCAL RÃ‰USSIS")
    print("=" * 60)
    print("\nğŸ“ RÃ©sumÃ©:")
    print("  â€¢ Provider LOCAL ajoutÃ© avec succÃ¨s")
    print("  â€¢ Configuration et validation fonctionnelles")
    print("  â€¢ Tests de connexion gÃ¨rent correctement les erreurs")
    print("  â€¢ Service IA compatible avec LOCAL")
    print("  â€¢ Interface graphique supporte LOCAL")
    print("\nğŸ’¡ Pour utiliser LOCAL:")
    print("  1. Installez Ollama: https://ollama.ai/")
    print("  2. DÃ©marrez un modÃ¨le: ollama run llama3.2")
    print("  3. Configurez l'URL: http://localhost:11434")
    print("  4. Testez la connexion dans l'interface")
    
    return True


def test_ollama_integration():
    """Test spÃ©cifique pour l'intÃ©gration Ollama"""
    print("\nğŸ¦™ Test spÃ©cifique Ollama...")
    
    try:
        # Test de l'URL Ollama par dÃ©faut
        from src.services.ai_config_service import get_ai_config_service
        config_service = get_ai_config_service()
        
        # Test de transformation d'URL
        test_urls = [
            "http://localhost:11434",
            "http://localhost:11434/",
            "http://localhost:11434/v1",
            "http://127.0.0.1:11434"
        ]
        
        for url in test_urls:
            config_service.set_base_url(AIProvider.LOCAL, url)
            stored_url = config_service.get_base_url(AIProvider.LOCAL)
            print(f"  ğŸ“ URL {url} -> {stored_url}")
        
        print("  âœ… Gestion des URLs Ollama fonctionnelle")
        return True
        
    except Exception as e:
        print(f"  âŒ Erreur test Ollama: {e}")
        return False


if __name__ == "__main__":
    print("ğŸš€ Lancement des tests d'intÃ©gration LOCAL...")
    
    success = test_local_provider_integration()
    
    if success:
        success = test_ollama_integration()
    
    if success:
        print("\nğŸ‰ Tous les tests sont RÃ‰USSIS !")
        print("Le provider LOCAL est prÃªt Ã  Ãªtre utilisÃ©.")
        exit(0)
    else:
        print("\nğŸ’¥ Certains tests ont Ã‰CHOUÃ‰.")
        print("VÃ©rifiez les erreurs ci-dessus.")
        exit(1) 